________________________________________________
             LEARNING IDENTITY TEST             
           aa_origine == aa_destination         
________________________________________________

____________________
  DATASET/DATALOAD  
____________________

DATASET with 9 amino-acids encoded from 0 to 8
N_NEIGHBOUR : 0
N_EXAMPLES (TOTAL): 4500
Example of one X_train, Y_train: (tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0]]), tensor([1, 0, 0, 0, 0, 0, 0, 0, 0]))
N_EXAMPLES_TRAIN: 3600
N_EXAMPLES_TEST: 900
(aa_origine == aa_destination) == True  # for all examples

____________________
  HYPER-PARAMETERS  
____________________

N_CLASSES : 9
INPUT_SIZE : 9
HIDDEN_SIZE : 100
N_EPOCHS : 2
BATCH_SIZE : 3
LEARNING_RATE : 0.001
TEST_SIZE : 0.2
RANDOM_STATE : 1234

____________________
        MODEL       
____________________

Feed Forward Neural Network with 1 HIDDEN LAYER + a final SOFTMAX LAYER
LOSS: MSELoss
OPTIMIZER: Adam

____________________
   TRAINING LOOP    
____________________

epoch 1 / 2, step 100/1200,                    loss = 0.0770
epoch 1 / 2, step 200/1200,                    loss = 0.0283
epoch 1 / 2, step 300/1200,                    loss = 0.0038
epoch 1 / 2, step 400/1200,                    loss = 0.0015
epoch 1 / 2, step 500/1200,                    loss = 0.0007
epoch 1 / 2, step 600/1200,                    loss = 0.0004
epoch 1 / 2, step 700/1200,                    loss = 0.0003
epoch 1 / 2, step 800/1200,                    loss = 0.0002
epoch 1 / 2, step 900/1200,                    loss = 0.0001
epoch 1 / 2, step 1000/1200,                    loss = 0.0001
epoch 1 / 2, step 1100/1200,                    loss = 0.0001
epoch 1 / 2, step 1200/1200,                    loss = 0.0001
epoch 2 / 2, step 100/1200,                    loss = 0.0001
epoch 2 / 2, step 200/1200,                    loss = 0.0001
epoch 2 / 2, step 300/1200,                    loss = 0.0000
epoch 2 / 2, step 400/1200,                    loss = 0.0000
epoch 2 / 2, step 500/1200,                    loss = 0.0000
epoch 2 / 2, step 600/1200,                    loss = 0.0000
epoch 2 / 2, step 700/1200,                    loss = 0.0000
epoch 2 / 2, step 800/1200,                    loss = 0.0000
epoch 2 / 2, step 900/1200,                    loss = 0.0000
epoch 2 / 2, step 1000/1200,                    loss = 0.0000
epoch 2 / 2, step 1100/1200,                    loss = 0.0000
epoch 2 / 2, step 1200/1200,                    loss = 0.0000

____________________
    TESTING LOOP    
____________________

Example of a test:
--Prediction:
 tensor([[1.8240e-03, 2.5160e-03, 2.6411e-03, 1.2710e-03, 2.4247e-03, 1.0931e-03,
         8.7020e-04, 1.8156e-03, 9.8554e-01],
        [1.1190e-03, 6.0675e-04, 1.3453e-03, 1.6440e-03, 2.2398e-03, 9.4883e-04,
         1.5403e-03, 9.8751e-01, 3.0489e-03],
        [2.2554e-03, 9.8824e-01, 1.2647e-03, 1.4237e-03, 1.6155e-03, 9.4836e-04,
         9.9881e-04, 4.4841e-04, 2.8092e-03]], device='cuda:0')
--Expected values:
 tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.],
        [0., 0., 0., 0., 0., 0., 0., 1., 0.],
        [0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')

Index of the Softmax MAX
--Prediction: tensor([8, 7, 1], device='cuda:0')
--Expected values: tensor([8, 7, 1], device='cuda:0')

ACCURACY: 100.0 %
